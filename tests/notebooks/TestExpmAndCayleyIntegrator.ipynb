{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOqYilyIAPowpS6WwTskmcE",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dnguyend/jax-rb/blob/main/tests/notebooks/TestExpmAndCayleyIntegrator.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# The Lie group exponential map and its second order approximations\n",
        "  * Since the package is not yet on pypi, use the dialog box below. Otherwise, on a terminal, download the repository then install locally.\n",
        "  \n",
        "  "
      ],
      "metadata": {
        "id": "MUJswQQKwQkY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install git+https://github.com/dnguyend/jax-rb"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wpJ5PwCM-CIa",
        "outputId": "4f4f4478-905e-4535-e5c5-135b56ab8fb5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting git+https://github.com/dnguyend/jax-rb\n",
            "  Cloning https://github.com/dnguyend/jax-rb to /tmp/pip-req-build-oa2a9hi1\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/dnguyend/jax-rb /tmp/pip-req-build-oa2a9hi1\n",
            "  Resolved https://github.com/dnguyend/jax-rb to commit 20efd03c04d80b3438f32dcbf48cd917036675b4\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: jax in /usr/local/lib/python3.10/dist-packages (from jax_rb==0.1.dev50+g20efd03) (0.4.26)\n",
            "Requirement already satisfied: jaxlib in /usr/local/lib/python3.10/dist-packages (from jax_rb==0.1.dev50+g20efd03) (0.4.26+cuda12.cudnn89)\n",
            "Requirement already satisfied: ml-dtypes>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from jax->jax_rb==0.1.dev50+g20efd03) (0.2.0)\n",
            "Requirement already satisfied: numpy>=1.22 in /usr/local/lib/python3.10/dist-packages (from jax->jax_rb==0.1.dev50+g20efd03) (1.25.2)\n",
            "Requirement already satisfied: opt-einsum in /usr/local/lib/python3.10/dist-packages (from jax->jax_rb==0.1.dev50+g20efd03) (3.3.0)\n",
            "Requirement already satisfied: scipy>=1.9 in /usr/local/lib/python3.10/dist-packages (from jax->jax_rb==0.1.dev50+g20efd03) (1.11.4)\n",
            "Building wheels for collected packages: jax_rb\n",
            "  Building wheel for jax_rb (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for jax_rb: filename=jax_rb-0.1.dev50+g20efd03-py3-none-any.whl size=33135 sha256=f24800b7a2d206c9e978d3abd86bf29f7eca9b81150400954a41b4ac54b236ec\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-lgolyt48/wheels/0f/76/88/65e675f8bcca47be98c588d9a787a4c1c9b0a5044517ba6490\n",
            "Successfully built jax_rb\n",
            "Installing collected packages: jax_rb\n",
            "Successfully installed jax_rb-0.1.dev50+g20efd03\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "$\\newcommand{\\R}{\\mathbb{R}}$\n",
        "$\\newcommand{\\fR}{\\mathfrak{r}}$\n",
        "$\\newcommand{\\so}{\\mathfrak{so}}$\n",
        "$\\newcommand{\\expm}{\\mathsf{expm}}$\n",
        "$\\newcommand{\\sigmam}{\\mathring{\\sigma}}$\n",
        "\n",
        "## The exponential retraction and the Cayley transform retraction.\n",
        "For a matrix Lie group $G$, the exponential retraction is given by\n",
        "$$\\fR(x, v) = x\\expm(x^{-1}v)\n",
        "$$\n",
        "where $v\\in T_xG$. We have the expansion\n",
        "$$\\fR(x, hv) = x + hv + \\frac{h^2}{2}x(x^{-1}v)^2 + O(h^3)\n",
        "$$\n",
        "Thus, the adjusted drift will be $\\mu_{\\fR} = \\mu - \\frac{1}{2}x(x^{-1}\\sigmam(x; E_{ij}))^2$ for the equation:\n",
        "$$dX = \\mu dt + \\sigmam(X)dW_t.$$\n",
        "For a random move $\\Delta_W \\sim N(0, h^{\\frac{1}{2}}I_{\\R^{N\\times N}})$, the  Euler-Maruyama exponential step will be\n",
        "$$X_{i+1} = X_i\\expm(X_i^{-1}(h\\mu_r(X_i)+ \\sigmam(X)\\Delta_W ))\n",
        "$$\n",
        "It is a [remarkable fact](https://en.wikipedia.org/wiki/Pad%C3%A9_approximant#cite_note-wolfram-alpha-pade-exp-11)  that the diagonal Pade approximator of $e^x$ is a rational function of the form $\\frac{p(x)}{p(-x)}$, with the first order approximation corresponds to $p(x) = 1+\\frac{x}{2}$.\n",
        "\n",
        "For the group SO(N), or (more generally, for quadratic Lie group [Celledoni and Iserle]), for $a\\in \\so(N)$, we have $p(-a)^{-1}p(a)$ is in $SO(N)$ for all analytic $p$ with real coefficients. With $p(x) = 1+\\frac{x}{2}$, we have the Cayley retraction\n",
        "\n",
        "$$\\fR_{Cayley}(x, v) = x(I-\\frac{1}{2}x^{-1}v)^{-1}(I+\\frac{1}{2}x^{-1}v),\n",
        "$$\n",
        "and the Euler-Maruyama Cayle steps will be\n",
        "$$X_{i+1} = X_i(I - \\frac{1}{2}X_i^{-1}(h\\mu_r(X_i)+ \\sigmam(X)\\Delta_W ))^{-1}\n",
        "(I + \\frac{1}{2}X_i^{-1}(h\\mu_r(X_i)+ \\sigmam(X)\\Delta_W ))\n",
        "$$\n",
        "We will check that these steps give the same simulation results as the geodesic, Ito and Stratonovich integrator in the paper.\n",
        "\n",
        "\n",
        "### References\n",
        "\n",
        "[Celledoni and Iserle] Celledoni, Elena, and Arieh Iserles. “Approximating the Exponential from a Lie Algebra to a Lie Group.” Mathematics of Computation, vol. 69, no. 232, 2000, pp. 1457–80. JSTOR, http://www.jstor.org/stable/2585076. Accessed 17 July 2024.\n"
      ],
      "metadata": {
        "id": "36nmu8MPHSfc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install git+https://github.com/dnguyend/jax-rb"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R50_I6ldmHMn",
        "outputId": "e64532f6-84ac-4d9b-dcec-2a06f1aff4bf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting git+https://github.com/dnguyend/jax-rb\n",
            "  Cloning https://github.com/dnguyend/jax-rb to /tmp/pip-req-build-_uzzt7oc\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/dnguyend/jax-rb /tmp/pip-req-build-_uzzt7oc\n",
            "  Resolved https://github.com/dnguyend/jax-rb to commit 20efd03c04d80b3438f32dcbf48cd917036675b4\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: jax in /usr/local/lib/python3.10/dist-packages (from jax_rb==0.1.dev50+g20efd03) (0.4.26)\n",
            "Requirement already satisfied: jaxlib in /usr/local/lib/python3.10/dist-packages (from jax_rb==0.1.dev50+g20efd03) (0.4.26+cuda12.cudnn89)\n",
            "Requirement already satisfied: ml-dtypes>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from jax->jax_rb==0.1.dev50+g20efd03) (0.2.0)\n",
            "Requirement already satisfied: numpy>=1.22 in /usr/local/lib/python3.10/dist-packages (from jax->jax_rb==0.1.dev50+g20efd03) (1.25.2)\n",
            "Requirement already satisfied: opt-einsum in /usr/local/lib/python3.10/dist-packages (from jax->jax_rb==0.1.dev50+g20efd03) (3.3.0)\n",
            "Requirement already satisfied: scipy>=1.9 in /usr/local/lib/python3.10/dist-packages (from jax->jax_rb==0.1.dev50+g20efd03) (1.11.4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QYVLILrQRLLO"
      },
      "outputs": [],
      "source": [
        "\"\"\"test simulation with the\n",
        "\"\"\"\n",
        "from functools import partial\n",
        "from time import perf_counter\n",
        "\n",
        "import jax\n",
        "import jax.numpy as jnp\n",
        "import jax.numpy.linalg as jla\n",
        "from jax import random, vmap, jit\n",
        "from jax.scipy.linalg import expm\n",
        "import jax_rb.manifolds.so_left_invariant as som\n",
        "import jax_rb.manifolds.se_left_invariant as sem\n",
        "import jax_rb.manifolds.affine_left_invariant as afm\n",
        "\n",
        "from jax_rb.utils.utils import (rand_positive_definite, sym, vcat)\n",
        "import jax_rb.simulation.simulator as sim\n",
        "import jax_rb.simulation.matrix_group_integrator as mi\n",
        "\n",
        "\n",
        "jax.config.update(\"jax_enable_x64\", True)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## A retractive step"
      ],
      "metadata": {
        "id": "bn1DIGtQvPQ1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "@partial(jit, static_argnums=(0,2,5,6))\n",
        "def matrix_retractive_move(rtr, x, t, unit_move, scale, sigma, mu):\n",
        "    \"\"\" Simulating the equation :math:`dX_t = \\\\mu(X_t, t) dt + \\\\sigma(X_t, t) dW_t` using the retraction rtr. The manifold is a Lie group.\n",
        "    We do not assume a Riemanian metric on the manifold, :math:`\\\\sigma\\\\sigma^T` could be degenerated on :math:`T\\\\mathcal{M}`. However, we create subclasses for left-invariant Lie groups.\n",
        "\n",
        "    W is a Wiener process driving the equation, defined on :math:`\\\\mathbb{R}^k`. W is given by unit_move.\n",
        "\n",
        "    :math:`\\\\sigma(X_t, t)` maps :math:`\\\\mathbb{R}^k` to :math:`\\\\mathcal{E}`, but the image belongs\n",
        "    to :math:`T_{X_t}\\\\mathcal{M}`.\n",
        "\n",
        "    The retraction rtr is assume to have the method :math:`\\\\text{drift_adj}` for an adjustment.\n",
        "\n",
        "    The move is :math:`x_{new} = \\\\mathfrak{r}(x, \\\\Pi(x)\\\\sigma(x)(\\\\text{unit_move}(\\\\text{scale})^{\\\\frac{1}{2}}) + \\\\text{scale} (\\\\mu + \\\\text{drift_adj}))`.\n",
        "\n",
        "    :param rtr: the retraction,\n",
        "    :param x: a point on the manifold,\n",
        "    :param t: time\n",
        "    :param unit_move: a random normal draw\n",
        "    :param scale: scaling\n",
        "    :param sigma: a function implementing the map :math:`\\\\sigma`\n",
        "    :param mu: a function implementing the Ito drift :math:`\\\\mu`\n",
        "    \"\"\"\n",
        "    return rtr.retract(x,\n",
        "                       sigma(x, t, unit_move.reshape(x.shape))*jnp.sqrt(scale)\n",
        "                       + scale*(mu(x, t) + rtr.drift_adjust(sigma, x, t, unit_move.shape[0])))\n"
      ],
      "metadata": {
        "id": "mIbxYgIAvuRx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "A few classes for retraction on groups and specialized implementations for $SO(n)$ and $SE(n)$. Here, we are in the case of Riemannian Brownian."
      ],
      "metadata": {
        "id": "PzJEj3XSnDgW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class expm_retraction():\n",
        "    \"\"\"the exmp retraction of a matrix Lie group\n",
        "    this is the most general, and not efficient implementation\n",
        "    for each lie group, we should have a custom implementation of this\n",
        "    \"\"\"\n",
        "    def __init__(self, mnf):\n",
        "        self.mnf = mnf\n",
        "\n",
        "    def retract(self, x, v):\n",
        "        \"\"\"rescaling :math:`x+v` to be on the manifold\n",
        "        \"\"\"\n",
        "        return x@expm(jla.solve(x, v))\n",
        "\n",
        "    def drift_adjust(self, sigma, x, t, driver_dim):\n",
        "        \"\"\"return the adjustment :math:`\\\\mu_{adj}`\n",
        "        so that :math:`\\\\mu + \\\\mu_{adj} = \\\\mu_{\\\\mathfrak{r}}`\n",
        "        \"\"\"\n",
        "\n",
        "        return -0.5*jnp.sum(vmap(lambda seq:\n",
        "                                 x@sqr(jla.solve(x, sigma(x, t, seq.reshape(x.shape)))))(jnp.eye(driver_dim)),\n",
        "                            axis=0)\n",
        "\n",
        "class cayley_so_retraction():\n",
        "    \"\"\"Cayley retraction of a matrix Lie group\n",
        "    this is the most general, and not efficient implementation\n",
        "    for each lie group, we should have a custom implementation of this\n",
        "    \"\"\"\n",
        "    def __init__(self, mnf):\n",
        "        self.mnf = mnf\n",
        "\n",
        "    def retract(self, x, v):\n",
        "        \"\"\"rescaling :math:`x+v` to be on the manifold\n",
        "        \"\"\"\n",
        "        ixv = x.T@v\n",
        "        return x + x@jla.solve(jnp.eye(ixv.shape[0]) - 0.5*ixv, ixv)\n",
        "\n",
        "    def drift_adjust(self, sigma, x, t, driver_dim):\n",
        "        \"\"\"return the adjustment :math:`\\\\mu_{adj}`\n",
        "        so that :math:`\\\\mu + \\\\mu_{adj} = \\\\mu_{\\\\mathfrak{r}}`\n",
        "        \"\"\"\n",
        "        return -0.5*jnp.sum(vmap(lambda seq:\n",
        "                                 x@sqr(self.mnf.sigma_id(seq.reshape(x.shape)))\n",
        "                                 )(jnp.eye(driver_dim)),\n",
        "                            axis=0)\n",
        "\n",
        "class cayley_se_retraction():\n",
        "    \"\"\"Cayley retraction of a matrix Lie group\n",
        "    this is the most general, and not efficient implementation\n",
        "    for each lie group, we should have a custom implementation of this\n",
        "    \"\"\"\n",
        "    def __init__(self, mnf):\n",
        "        self.mnf = mnf\n",
        "\n",
        "    def retract(self, x, v):\n",
        "        \"\"\"rescaling :math:`x+v` to be on the manifold\n",
        "        \"\"\"\n",
        "        n = x.shape[0] - 1\n",
        "        ixva = x[:-1, :-1].T@v[:-1, :-1]\n",
        "        return vcat(jnp.concatenate([x[:-1, :-1] + x[:-1, :-1]@jla.solve(jnp.eye(n)-0.5*ixva, ixva),\n",
        "                                     jla.solve(jnp.eye(n)-0.5*ixva, v[:-1, n:])], axis=1),\n",
        "                    jnp.zeros(x.shape[0]).at[-1].set(1.).reshape(1, -1))\n",
        "    # x + x@jla.solve(jnp.eye(ixv.shape[0]) - 0.5*ixv, ixv)\n",
        "\n",
        "    def drift_adjust(self, sigma, x, t, driver_dim):\n",
        "        \"\"\"return the adjustment :math:`\\\\mu_{adj}`\n",
        "        so that :math:`\\\\mu + \\\\mu_{adj} = \\\\mu_{\\\\mathfrak{r}}`\n",
        "        \"\"\"\n",
        "        return -0.5*jnp.sum(vmap(lambda seq:\n",
        "                                 x@sqr(self.mnf.sigma_id(seq.reshape(x.shape)))\n",
        "                                 )(jnp.eye(driver_dim)),\n",
        "                            axis=0)\n",
        "\n",
        "def sqr(a):\n",
        "    return a@a\n"
      ],
      "metadata": {
        "id": "7A5PZbZ1msZg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Test for $SO(n)$\n",
        "We test the adjusted ito_drift is tangent, double check that it is -sum of gamma."
      ],
      "metadata": {
        "id": "umfUNVfXwe8v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def test_expm_integrator_so():\n",
        "    n = 5\n",
        "    key = random.PRNGKey(0)\n",
        "    so_dim = n*(n-1)//2\n",
        "    metric_mat, key = rand_positive_definite(key, so_dim, (.1, 10.))\n",
        "    mnf = som.SOLeftInvariant(n, metric_mat)\n",
        "    x, key = mnf.rand_point(key)\n",
        "\n",
        "    gsum = jnp.zeros((n, n))\n",
        "    hsum = jnp.zeros((n, n))\n",
        "    for i in range(n**2):\n",
        "        nsg = mnf.proj(x, mnf.sigma(x, jnp.zeros(n**2).at[i].set(1.).reshape(n, n)))\n",
        "        hsum += x@sqr(x.T@nsg)\n",
        "        gsum += - mnf.gamma(x, nsg, nsg)\n",
        "        # print(jnp.sum(mnf.grad_c(x)*(hsum-gsum)))\n",
        "\n",
        "    print(f\"test sum -gamma - ito drift={0.5*gsum - mnf.ito_drift(x)}\")\n",
        "    print(f\"test adjusted ito is tangent={sym(x.T@(-0.5*hsum+mnf.ito_drift(x)))}\")\n",
        "\n",
        "    # now test the equation.\n",
        "    # test Brownian motion\n",
        "    def new_sigma(x, _, dw):\n",
        "        return mnf.proj(x, mnf.sigma(x, dw))\n",
        "\n",
        "    def mu(x, _):\n",
        "        return mnf.ito_drift(x)\n",
        "\n",
        "    pay_offs = [lambda x, t: t*jnp.sum(x*jnp.arange(n)),\n",
        "                lambda x: jnp.sqrt(jnp.sum(x*x))]\n",
        "\n",
        "    key, sk = random.split(key)\n",
        "    t_final = 1.\n",
        "    n_path = 1000\n",
        "    n_div = 1000\n",
        "    d_coeff = .5\n",
        "    wiener_dim = n**2\n",
        "    x_0 = jnp.eye(n)\n",
        "\n",
        "    ret_geo = sim.simulate(x_0,\n",
        "                           lambda x, unit_move, scale: mi.geodesic_move(\n",
        "                               mnf, x, unit_move, scale),\n",
        "                           pay_offs[0],\n",
        "                           pay_offs[1],\n",
        "                           [sk, t_final, n_path, n_div, d_coeff, wiener_dim])\n",
        "\n",
        "    ret_ito = sim.simulate(x_0,\n",
        "                           lambda x, unit_move, scale: mi.rbrownian_ito_move(\n",
        "                               mnf, x, unit_move, scale),\n",
        "                           pay_offs[0],\n",
        "                           pay_offs[1],\n",
        "                           [sk, t_final, n_path, n_div, d_coeff, wiener_dim])\n",
        "\n",
        "    ret_str = sim.simulate(x_0,\n",
        "                           lambda x, unit_move, scale: mi.rbrownian_stratonovich_move(\n",
        "                               mnf, x, unit_move, scale),\n",
        "                           pay_offs[0],\n",
        "                           pay_offs[1],\n",
        "                           [sk, t_final, n_path, n_div, d_coeff, wiener_dim])\n",
        "\n",
        "    rtr = expm_retraction(mnf)\n",
        "    # a warm up run\n",
        "    ret_rtr = sim.simulate(x_0,\n",
        "                           lambda x, unit_move, scale: matrix_retractive_move(\n",
        "                               rtr, x, 1., unit_move, scale, new_sigma, mu),\n",
        "                           pay_offs[0],\n",
        "                           pay_offs[1],\n",
        "                           [sk, t_final, 5, 5, d_coeff, wiener_dim])\n",
        "\n",
        "    t0 = perf_counter()\n",
        "    ret_rtr = sim.simulate(x_0,\n",
        "                           lambda x, unit_move, scale: matrix_retractive_move(\n",
        "                               rtr, x, 1., unit_move, scale, new_sigma, mu),\n",
        "                           pay_offs[0],\n",
        "                           pay_offs[1],\n",
        "                           [sk, t_final, n_path, n_div, d_coeff, wiener_dim])\n",
        "    t1 = perf_counter()\n",
        "    print('Time rtr %f' % (t1-t0))\n",
        "\n",
        "    crtr = cayley_so_retraction(mnf)\n",
        "    t4 = perf_counter()\n",
        "    ret_crtr = sim.simulate(x_0,\n",
        "                           lambda x, unit_move, scale: matrix_retractive_move(\n",
        "                               crtr, x, 1., unit_move, scale, new_sigma, mu),\n",
        "                           pay_offs[0],\n",
        "                           pay_offs[1],\n",
        "                           [sk, t_final, n_path, n_div, d_coeff, wiener_dim])\n",
        "    t5 = perf_counter()\n",
        "    print('Time crtr %f' % (t5-t4))\n",
        "\n",
        "    print(f\"geo second order = {jnp.nanmean(ret_geo[0])}\")\n",
        "    print(f\"Ito              = {jnp.nanmean(ret_ito[0])}\")\n",
        "    print(f\"Stratonovich     = {jnp.nanmean(ret_str[0])}\")\n",
        "    print(f\"Retractive       = {jnp.nanmean(ret_rtr[0])}\")\n",
        "    print(f\"expm_so_Retractive       = {jnp.nanmean(ret_rtr[0])}\")\n",
        "    print(f\"Cayley Retractive       = {jnp.nanmean(ret_crtr[0])}\")\n",
        "\n",
        "test_expm_integrator_so()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hp0BDZJowmDX",
        "outputId": "12419e30-f42a-495a-9039-45d7f839567a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "test sum -gamma - ito drift=[[-3.26128013e-16  2.08166817e-16  1.66533454e-16  8.32667268e-17\n",
            "   6.24500451e-17]\n",
            " [-7.97972799e-17 -8.32667268e-17 -1.11022302e-16 -1.80411242e-16\n",
            "  -3.60822483e-16]\n",
            " [ 3.12250226e-17 -3.60822483e-16  6.93889390e-17 -2.77555756e-17\n",
            "  -2.22044605e-16]\n",
            " [-8.32667268e-17 -2.08166817e-16  1.24900090e-16 -2.77555756e-17\n",
            "  -2.49800181e-16]\n",
            " [ 0.00000000e+00 -5.55111512e-17 -1.52655666e-16  4.85722573e-17\n",
            "   2.08166817e-16]]\n",
            "test adjusted ito is tangent=[[-2.37661530e-16 -2.22460559e-17 -1.90646870e-16 -7.17538281e-17\n",
            "   1.26459054e-16]\n",
            " [-2.22460559e-17  3.04724698e-16  3.08194244e-17  1.62580828e-17\n",
            "   1.29192211e-16]\n",
            " [-1.90646870e-16  3.08194244e-17  5.47579078e-17  1.45219969e-16\n",
            "   6.05938757e-17]\n",
            " [-7.17538281e-17  1.62580828e-17  1.45219969e-16 -1.71952758e-17\n",
            "   5.51827559e-17]\n",
            " [ 1.26459054e-16  1.29192211e-16  6.05938757e-17  5.51827559e-17\n",
            "   4.28030441e-16]]\n",
            "Time rtr 73.857657\n",
            "Time crtr 20.281238\n",
            "geo second order = 6.056695178129371\n",
            "Ito              = 6.055929373235796\n",
            "Stratonovich     = 6.054953057202997\n",
            "Retractive       = 6.055528965229489\n",
            "expm_so_Retractive       = 6.055528965229489\n",
            "Cayley Retractive       = 6.05581697657123\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Test SE. The integrator for SE"
      ],
      "metadata": {
        "id": "KSyq6UHQuxYJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def test_expm_integrator_se():\n",
        "    n = 3\n",
        "    key = random.PRNGKey(0)\n",
        "    se_dim = n*(n+1)//2\n",
        "    metric_mat, key = rand_positive_definite(key, se_dim, (.1, 30.))\n",
        "    mnf = sem.SELeftInvariant(n, metric_mat)\n",
        "    x, key = mnf.rand_point(key)\n",
        "    n1 = n+1\n",
        "\n",
        "    gsum = jnp.zeros((n1, n1))\n",
        "    hsum = jnp.zeros((n1, n1))\n",
        "    for i in range(n1**2):\n",
        "        nsg = mnf.proj(x, mnf.sigma(x, jnp.zeros(n1**2).at[i].set(1.).reshape(n1, n1)))\n",
        "        hsum += x@sqr(jla.solve(x, nsg))\n",
        "        gsum += - mnf.gamma(x, nsg, nsg)\n",
        "        # print(jnp.sum(mnf.grad_c(x)*(hsum-gsum)))\n",
        "\n",
        "    print(f\"test sum -gamma - ito drift={0.5*gsum - mnf.ito_drift(x)}\")\n",
        "    print(f\"test adjusted ito is tangent={sym(x.T@(-0.5*hsum+mnf.ito_drift(x)))}\")\n",
        "\n",
        "    # now test the equation.\n",
        "    # test Brownian motion\n",
        "\n",
        "    def new_sigma(x, _, dw):\n",
        "        return mnf.proj(x, mnf.sigma(x, dw))\n",
        "\n",
        "    def mu(x, _):\n",
        "        return mnf.ito_drift(x)\n",
        "\n",
        "    pay_offs = [lambda x, t: t*jnp.maximum(x[0, 0]-.5, 0),\n",
        "                lambda x: x[0, 0]**2]\n",
        "\n",
        "    key, sk = random.split(key)\n",
        "    t_final = 1.\n",
        "    n_path = 1000\n",
        "    n_div = 1000\n",
        "    d_coeff = .5\n",
        "    wiener_dim = n1**2\n",
        "    x_0 = jnp.eye(n1)\n",
        "\n",
        "    ret_geo = sim.simulate(x_0,\n",
        "                           lambda x, unit_move, scale: mi.geodesic_move(\n",
        "                               mnf, x, unit_move, scale),\n",
        "                           pay_offs[0],\n",
        "                           pay_offs[1],\n",
        "                           [sk, t_final, n_path, n_div, d_coeff, wiener_dim])\n",
        "\n",
        "    ret_ito = sim.simulate(x_0,\n",
        "                           lambda x, unit_move, scale: mi.rbrownian_ito_move(\n",
        "                               mnf, x, unit_move, scale),\n",
        "                           pay_offs[0],\n",
        "                           pay_offs[1],\n",
        "                           [sk, t_final, n_path, n_div, d_coeff, wiener_dim])\n",
        "\n",
        "    ret_str = sim.simulate(x_0,\n",
        "                           lambda x, unit_move, scale: mi.rbrownian_stratonovich_move(\n",
        "                               mnf, x, unit_move, scale),\n",
        "                           pay_offs[0],\n",
        "                           pay_offs[1],\n",
        "                           [sk, t_final, n_path, n_div, d_coeff, wiener_dim])\n",
        "    rtr = expm_retraction(mnf)\n",
        "    ret_rtr = sim.simulate(x_0,\n",
        "                           lambda x, unit_move, scale: matrix_retractive_move(\n",
        "                               rtr, x, 1., unit_move, scale, new_sigma, mu),\n",
        "                           pay_offs[0],\n",
        "                           pay_offs[1],\n",
        "                           [sk, t_final, 5, 5, d_coeff, wiener_dim])\n",
        "\n",
        "    t0 = perf_counter()\n",
        "    ret_rtr = sim.simulate(x_0,\n",
        "                           lambda x, unit_move, scale: matrix_retractive_move(\n",
        "                               rtr, x, 1., unit_move, scale, new_sigma, mu),\n",
        "                           pay_offs[0],\n",
        "                           pay_offs[1],\n",
        "                           [sk, t_final, n_path, n_div, d_coeff, wiener_dim])\n",
        "    t1 = perf_counter()\n",
        "    print('Time rtr %f' % (t1-t0))\n",
        "\n",
        "    crtr = cayley_se_retraction(mnf)\n",
        "    t4 = perf_counter()\n",
        "    ret_crtr = sim.simulate(x_0,\n",
        "                           lambda x, unit_move, scale: matrix_retractive_move(\n",
        "                               crtr, x, 1., unit_move, scale, new_sigma, mu),\n",
        "                           pay_offs[0],\n",
        "                           pay_offs[1],\n",
        "                           [sk, t_final, n_path, n_div, d_coeff, wiener_dim])\n",
        "    t5 = perf_counter()\n",
        "    print('Time crtr %f' % (t5-t4))\n",
        "\n",
        "    print(f\"geo second order = {jnp.nanmean(ret_geo[0])}\")\n",
        "    print(f\"Ito              = {jnp.nanmean(ret_ito[0])}\")\n",
        "    print(f\"Stratonovich     = {jnp.nanmean(ret_str[0])}\")\n",
        "    print(f\"Retractive       = {jnp.nanmean(ret_rtr[0])}\")\n",
        "    print(f\"Cayley Retractive       = {jnp.nanmean(ret_crtr[0])}\")\n",
        "test_expm_integrator_se()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TlZkYHY4uvgB",
        "outputId": "0c950e9e-e80a-4a20-addc-adaf2d280593"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "test sum -gamma - ito drift=[[ 1.17961196e-16  9.02056208e-17  7.63278329e-17  2.77555756e-17]\n",
            " [-5.55111512e-17 -4.94396191e-17 -6.93889390e-17 -3.64291930e-17]\n",
            " [ 9.02056208e-17  7.28583860e-17 -1.38777878e-16  2.77555756e-17]\n",
            " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00]]\n",
            "test adjusted ito is tangent=[[ 1.28024894e-16  9.54199437e-17 -2.23648658e-17 -2.70499180e-17]\n",
            " [ 9.54199437e-17  5.49101560e-17  2.59732528e-17 -1.82677302e-17]\n",
            " [-2.23648658e-17  2.59732528e-17  1.49963480e-16 -7.62769047e-18]\n",
            " [-2.70499180e-17 -1.82677302e-17 -7.62769047e-18 -1.42003740e-16]]\n",
            "Time rtr 42.457243\n",
            "Time crtr 14.400974\n",
            "geo second order = 1.1363965505646139\n",
            "Ito              = 1.136390973605797\n",
            "Stratonovich     = 1.1363671560250506\n",
            "Retractive       = 1.1363802045207878\n",
            "Cayley Retractive       = 1.1363867289743548\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# A simple approximation of expm\n",
        " The two-terms Taylor series. For most groups, this does not work, but for the affine group and the generalized linear group, this works."
      ],
      "metadata": {
        "id": "-F3_McSfN4lu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class expm_apprx_retraction():\n",
        "    \"\"\"the a retractive approximation of expm. This is simply a Taylor expansion\n",
        "    it works for affine group and GL(n), but the second Taylor expansion\n",
        "    in general is not a retraction. The other type is pade\n",
        "    \"\"\"\n",
        "    def __init__(self, mnf):\n",
        "        self.mnf = mnf\n",
        "\n",
        "    def retract(self, x, v):\n",
        "        \"\"\"rescaling :math:`x+v` to be on the manifold\n",
        "        \"\"\"\n",
        "        return x + v + 0.5*x@sqr(jla.solve(x, v))\n",
        "\n",
        "    def drift_adjust(self, _, x, t, driver_dim):\n",
        "        \"\"\"return the adjustment :math:`\\\\mu_{adj}`\n",
        "        so that :math:`\\\\mu + \\\\mu_{adj} = \\\\mu_{\\\\mathfrak{r}}`\n",
        "        \"\"\"\n",
        "\n",
        "        return -0.5*jnp.sum(vmap(lambda seq:\n",
        "                                 x@sqr(self.mnf.sigma_id(seq.reshape(x.shape))))(jnp.eye(driver_dim)),\n",
        "                            axis=0)\n"
      ],
      "metadata": {
        "id": "OJSr4lXWN3Sf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Again, test the adjusted ito is tangent, then show the expm and the two terms taylor series simulations give the same result as the other 3 simulations"
      ],
      "metadata": {
        "id": "UyP3uTdkPrgp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def test_expm_integrator_affine():\n",
        "    n = 3\n",
        "    aff_dim = n*(n+1)\n",
        "    n1 = n + 1\n",
        "\n",
        "    key = random.PRNGKey(0)\n",
        "    metric_mat, key = rand_positive_definite(key, aff_dim, (.1, 10.))\n",
        "    mnf = afm.AffineLeftInvariant(n, metric_mat)\n",
        "\n",
        "    x, key = mnf.rand_point(key)\n",
        "\n",
        "    gsum = jnp.zeros((n1, n1))\n",
        "    hsum = jnp.zeros((n1, n1))\n",
        "    for i in range(n1**2):\n",
        "        nsg = mnf.proj(x, mnf.sigma(x, jnp.zeros(n1**2).at[i].set(1.).reshape(n1, n1)))\n",
        "        hsum += x@sqr(jla.solve(x, nsg))\n",
        "        gsum += - mnf.gamma(x, nsg, nsg)\n",
        "        # print(jnp.sum(mnf.grad_c(x)*(hsum-gsum)))\n",
        "\n",
        "    print(f\"test sum -gamma - ito drift={0.5*gsum - mnf.ito_drift(x)}\")\n",
        "    print(f\"test adjusted ito is tangent={jla.solve(x, (-0.5*hsum+mnf.ito_drift(x)))}\")\n",
        "\n",
        "    # now test the equation.\n",
        "    # test Brownian motion\n",
        "\n",
        "    def new_sigma(x, _, dw):\n",
        "        return mnf.proj(x, mnf.sigma(x, dw))\n",
        "\n",
        "    def mu(x, _):\n",
        "        return mnf.ito_drift(x)\n",
        "\n",
        "    pay_offs = [lambda x, t: t*jnp.maximum(x[0, 0]-.5, 0),\n",
        "                lambda x: (1+jnp.abs(x[0, 0]))**(-.5)\n",
        "                ]\n",
        "\n",
        "\n",
        "    key, sk = random.split(key)\n",
        "    t_final = 1.\n",
        "    n_path = 1000\n",
        "    n_div = 200\n",
        "    d_coeff = .5\n",
        "    wiener_dim = n1**2\n",
        "    x_0 = jnp.eye(n1)\n",
        "\n",
        "    ret_geo = sim.simulate(x_0,\n",
        "                           lambda x, unit_move, scale: mi.geodesic_move(\n",
        "                               mnf, x, unit_move, scale),\n",
        "                           pay_offs[0],\n",
        "                           pay_offs[1],\n",
        "                           [sk, t_final, n_path, n_div, d_coeff, wiener_dim])\n",
        "\n",
        "    ret_ito = sim.simulate(x_0,\n",
        "                           lambda x, unit_move, scale: mi.rbrownian_ito_move(\n",
        "                               mnf, x, unit_move, scale),\n",
        "                           pay_offs[0],\n",
        "                           pay_offs[1],\n",
        "                           [sk, t_final, n_path, n_div, d_coeff, wiener_dim])\n",
        "\n",
        "    ret_str = sim.simulate(x_0,\n",
        "                           lambda x, unit_move, scale: mi.rbrownian_stratonovich_move(\n",
        "                               mnf, x, unit_move, scale),\n",
        "                           pay_offs[0],\n",
        "                           pay_offs[1],\n",
        "                           [sk, t_final, n_path, n_div, d_coeff, wiener_dim])\n",
        "\n",
        "    rtr = expm_retraction(mnf)\n",
        "    t0 = perf_counter()\n",
        "    ret_rtr = sim.simulate(x_0,\n",
        "                           lambda x, unit_move, scale: matrix_retractive_move(\n",
        "                               rtr, x, None, unit_move, scale, new_sigma, mu),\n",
        "                           pay_offs[0],\n",
        "                           pay_offs[1],\n",
        "                           [sk, t_final, n_path, n_div, d_coeff, wiener_dim])\n",
        "    t1 = perf_counter()\n",
        "    print('Time rtr %f' % (t1-t0))\n",
        "\n",
        "    artr = expm_apprx_retraction(mnf)\n",
        "    t2 = perf_counter()\n",
        "    ret_artr = sim.simulate(x_0,\n",
        "                           lambda x, unit_move, scale: matrix_retractive_move(\n",
        "                               artr, x, None, unit_move, scale, new_sigma, mu),\n",
        "                            pay_offs[0],\n",
        "                            pay_offs[1],\n",
        "                            [sk, t_final, n_path, n_div, d_coeff, wiener_dim])\n",
        "    t3 = perf_counter()\n",
        "    print('Time artr %f' % (t3-t2))\n",
        "\n",
        "    print(f\"geo second order = {jnp.nanmean(ret_geo[0])}\")\n",
        "    print(f\"Ito              = {jnp.nanmean(ret_ito[0])}\")\n",
        "    print(f\"Stratonovich     = {jnp.nanmean(ret_str[0])}\")\n",
        "    print(f\"Retractive       = {jnp.nanmean(ret_rtr[0])}\")\n",
        "    print(f\"Appx Exp Retractive       = {jnp.nanmean(ret_artr[0])}\")\n",
        "\n",
        "test_expm_integrator_affine()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WD-SSgqMPFTq",
        "outputId": "1dce2e27-30d4-45d8-9811-cb115a861008"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "test sum -gamma - ito drift=[[ 3.57353036e-16 -8.88178420e-16  1.04083409e-16 -1.56125113e-16]\n",
            " [-2.08166817e-16 -3.46944695e-18  6.93889390e-17  1.87350135e-16]\n",
            " [ 3.95516953e-16 -3.74700271e-16 -3.98986399e-16 -2.84494650e-16]\n",
            " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00]]\n",
            "test adjusted ito is tangent=[[-0.05771071  0.03133447 -0.01165553 -0.03045669]\n",
            " [ 0.03785821 -0.20563126  0.03272205  0.04153271]\n",
            " [ 0.0002595   0.04121875 -0.13468639  0.03533443]\n",
            " [ 0.          0.          0.          0.        ]]\n",
            "Time rtr 11.436188\n",
            "Time artr 2.475534\n",
            "geo second order = 0.985876600067447\n",
            "Ito              = 0.985415106027261\n",
            "Stratonovich     = 0.9857234685704925\n",
            "Retractive       = 0.9857389429799134\n",
            "Appx Exp Retractive       = 0.9856962692286884\n"
          ]
        }
      ]
    }
  ]
}