{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyM6M9Arew2I3GJUj0pDfjVV"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# The Lie group exponential map and its second order approximations\n",
        "  * Since the package is not yet on pypi, use the dialog box below. Otherwise, on a terminal, download the repository then install locally.\n",
        "  \n",
        "  "
      ],
      "metadata": {
        "id": "MUJswQQKwQkY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install git+https://github.com/dnguyend/jax-rb"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wpJ5PwCM-CIa",
        "outputId": "de4b8528-7bfc-4c8e-b071-dbedcbbf47c4"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting git+https://github.com/dnguyend/jax-rb\n",
            "  Cloning https://github.com/dnguyend/jax-rb to /tmp/pip-req-build-lsy3c8_z\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/dnguyend/jax-rb /tmp/pip-req-build-lsy3c8_z\n",
            "  Resolved https://github.com/dnguyend/jax-rb to commit 581cc9d9b79fd59e4e49f03ca352f9b35c65ae65\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: jax in /usr/local/lib/python3.10/dist-packages (from jax_rb==0.1.dev57+g581cc9d) (0.4.26)\n",
            "Requirement already satisfied: jaxlib in /usr/local/lib/python3.10/dist-packages (from jax_rb==0.1.dev57+g581cc9d) (0.4.26+cuda12.cudnn89)\n",
            "Requirement already satisfied: ml-dtypes>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from jax->jax_rb==0.1.dev57+g581cc9d) (0.2.0)\n",
            "Requirement already satisfied: numpy>=1.22 in /usr/local/lib/python3.10/dist-packages (from jax->jax_rb==0.1.dev57+g581cc9d) (1.25.2)\n",
            "Requirement already satisfied: opt-einsum in /usr/local/lib/python3.10/dist-packages (from jax->jax_rb==0.1.dev57+g581cc9d) (3.3.0)\n",
            "Requirement already satisfied: scipy>=1.9 in /usr/local/lib/python3.10/dist-packages (from jax->jax_rb==0.1.dev57+g581cc9d) (1.13.1)\n",
            "Building wheels for collected packages: jax_rb\n",
            "  Building wheel for jax_rb (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for jax_rb: filename=jax_rb-0.1.dev57+g581cc9d-py3-none-any.whl size=33706 sha256=c4c979ea7f80ff92e40bcf9dea861d559273b4ea6131973c353c83213783be2a\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-tsmvnpug/wheels/0f/76/88/65e675f8bcca47be98c588d9a787a4c1c9b0a5044517ba6490\n",
            "Successfully built jax_rb\n",
            "Installing collected packages: jax_rb\n",
            "Successfully installed jax_rb-0.1.dev57+g581cc9d\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "$\\newcommand{\\R}{\\mathbb{R}}$\n",
        "$\\newcommand{\\fR}{\\mathfrak{r}}$\n",
        "$\\newcommand{\\so}{\\mathfrak{so}}$\n",
        "$\\newcommand{\\expm}{\\mathsf{expm}}$\n",
        "$\\newcommand{\\sigmam}{\\mathring{\\sigma}}$\n",
        "\n",
        "## The exponential retraction and the Cayley transform retraction.\n",
        "For a matrix Lie group $G$, the exponential retraction is given by\n",
        "$$\\fR(x, v) = x\\expm(x^{-1}v)\n",
        "$$\n",
        "where $v\\in T_xG$. We have the expansion\n",
        "$$\\fR(x, hv) = x + hv + \\frac{h^2}{2}x(x^{-1}v)^2 + O(h^3)\n",
        "$$\n",
        "Thus, the adjusted drift will be $\\mu_{\\fR} = \\mu - \\frac{1}{2}x(x^{-1}\\sigmam(x; E_{ij}))^2$ for the equation:\n",
        "$$dX = \\mu dt + \\sigmam(X)dW_t.$$\n",
        "For a random move $\\Delta_W \\sim N(0, h^{\\frac{1}{2}}I_{\\R^{N\\times N}})$, the  Euler-Maruyama exponential step will be\n",
        "$$X_{i+1} = X_i\\expm(X_i^{-1}(h\\mu_r(X_i)+ \\sigmam(X)\\Delta_W ))\n",
        "$$\n",
        "It is a [remarkable fact](https://en.wikipedia.org/wiki/Pad%C3%A9_approximant#cite_note-wolfram-alpha-pade-exp-11)  that the diagonal Pade approximator of $e^x$ is a rational function of the form $\\frac{p(x)}{p(-x)}$, with the first approximation corresponds to $p(x) = 1+\\frac{x}{2}$.\n",
        "\n",
        "For the group SO(N), or (more generally, for quadratic Lie group [Celledoni and Iserle]), for $a\\in \\so(N)$, we have $p(-a)^{-1}p(a)$ is in $SO(N)$ for all analytic $p$ with real coefficients. With $p(x) = 1+\\frac{x}{2}$, we have the Cayley retraction\n",
        "\n",
        "$$\\fR_{Cayley}(x, v) = x(I-\\frac{1}{2}x^{-1}v)^{-1}(I+\\frac{1}{2}x^{-1}v),\n",
        "$$\n",
        "and the Euler-Maruyama Cayle steps will be\n",
        "$$X_{i+1} = X_i(I - \\frac{1}{2}X_i^{-1}(h\\mu_r(X_i)+ \\sigmam(X)\\Delta_W ))^{-1}\n",
        "(I + \\frac{1}{2}X_i^{-1}(h\\mu_r(X_i)+ \\sigmam(X)\\Delta_W ))\n",
        "$$\n",
        "We will check that these steps give the same simulation results as the geodesic, Ito and Stratonovich integrator in the paper. Beyond SO(n), when the group is not compact, the error growth is difficult to control for long term simulations.\n",
        "\n",
        "\n",
        "### References\n",
        "\n",
        "[Celledoni and Iserle] Celledoni, Elena, and Arieh Iserles. “Approximating the Exponential from a Lie Algebra to a Lie Group.” Mathematics of Computation, vol. 69, no. 232, 2000, pp. 1457–80. JSTOR, http://www.jstor.org/stable/2585076. Accessed 17 July 2024.\n"
      ],
      "metadata": {
        "id": "36nmu8MPHSfc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install git+https://github.com/dnguyend/jax-rb"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R50_I6ldmHMn",
        "outputId": "8222b66f-56f0-4d60-b207-7020c8dbe934"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting git+https://github.com/dnguyend/jax-rb\n",
            "  Cloning https://github.com/dnguyend/jax-rb to /tmp/pip-req-build-cvhpd3gb\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/dnguyend/jax-rb /tmp/pip-req-build-cvhpd3gb\n",
            "  Resolved https://github.com/dnguyend/jax-rb to commit 581cc9d9b79fd59e4e49f03ca352f9b35c65ae65\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: jax in /usr/local/lib/python3.10/dist-packages (from jax_rb==0.1.dev57+g581cc9d) (0.4.26)\n",
            "Requirement already satisfied: jaxlib in /usr/local/lib/python3.10/dist-packages (from jax_rb==0.1.dev57+g581cc9d) (0.4.26+cuda12.cudnn89)\n",
            "Requirement already satisfied: ml-dtypes>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from jax->jax_rb==0.1.dev57+g581cc9d) (0.2.0)\n",
            "Requirement already satisfied: numpy>=1.22 in /usr/local/lib/python3.10/dist-packages (from jax->jax_rb==0.1.dev57+g581cc9d) (1.25.2)\n",
            "Requirement already satisfied: opt-einsum in /usr/local/lib/python3.10/dist-packages (from jax->jax_rb==0.1.dev57+g581cc9d) (3.3.0)\n",
            "Requirement already satisfied: scipy>=1.9 in /usr/local/lib/python3.10/dist-packages (from jax->jax_rb==0.1.dev57+g581cc9d) (1.13.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "QYVLILrQRLLO"
      },
      "outputs": [],
      "source": [
        "\"\"\"test simulation with the\n",
        "\"\"\"\n",
        "from functools import partial\n",
        "from time import perf_counter\n",
        "\n",
        "import jax\n",
        "import jax.numpy as jnp\n",
        "import jax.numpy.linalg as jla\n",
        "from jax import random, vmap, jit\n",
        "from jax.scipy.linalg import expm\n",
        "import jax_rb.manifolds.so_left_invariant as som\n",
        "\n",
        "from jax_rb.utils.utils import (rand_positive_definite, sym, vcat)\n",
        "import jax_rb.simulation.simulator as sim\n",
        "import jax_rb.simulation.matrix_group_integrator as mi\n",
        "\n",
        "\n",
        "jax.config.update(\"jax_enable_x64\", True)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## A retractive step"
      ],
      "metadata": {
        "id": "bn1DIGtQvPQ1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "@partial(jit, static_argnums=(0,2,5,6))\n",
        "def matrix_retractive_move(rtr, x, t, unit_move, scale, sigma, mu):\n",
        "    \"\"\" Simulating the equation :math:`dX_t = \\\\mu(X_t, t) dt + \\\\sigma(X_t, t) dW_t` using the retraction rtr. The manifold is a Lie group.\n",
        "    We do not assume a Riemanian metric on the manifold, :math:`\\\\sigma\\\\sigma^T` could be degenerated on :math:`T\\\\mathcal{M}`. However, we create subclasses for left-invariant Lie groups.\n",
        "\n",
        "    W is a Wiener process driving the equation, defined on :math:`\\\\mathbb{R}^k`. W is given by unit_move.\n",
        "\n",
        "    :math:`\\\\sigma(X_t, t)` maps :math:`\\\\mathbb{R}^k` to :math:`\\\\mathcal{E}`, but the image belongs\n",
        "    to :math:`T_{X_t}\\\\mathcal{M}`.\n",
        "\n",
        "    The retraction rtr is assume to have the method :math:`\\\\text{drift_adj}` for an adjustment.\n",
        "\n",
        "    The move is :math:`x_{new} = \\\\mathfrak{r}(x, \\\\Pi(x)\\\\sigma(x)(\\\\text{unit_move}(\\\\text{scale})^{\\\\frac{1}{2}}) + \\\\text{scale} (\\\\mu + \\\\text{drift_adj}))`.\n",
        "\n",
        "    :param rtr: the retraction,\n",
        "    :param x: a point on the manifold,\n",
        "    :param t: time\n",
        "    :param unit_move: a random normal draw\n",
        "    :param scale: scaling\n",
        "    :param sigma: a function implementing the map :math:`\\\\sigma`\n",
        "    :param mu: a function implementing the Ito drift :math:`\\\\mu`\n",
        "    \"\"\"\n",
        "    return rtr.retract(x,\n",
        "                       sigma(x, t, unit_move.reshape(x.shape))*jnp.sqrt(scale)\n",
        "                       + scale*(mu(x, t) + rtr.drift_adjust(sigma, x, t, unit_move.shape[0])))\n"
      ],
      "metadata": {
        "id": "mIbxYgIAvuRx"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "A few classes for retraction on groups and specialized implementations for $SO(n)$. Here, we are in the case of Riemannian Brownian."
      ],
      "metadata": {
        "id": "PzJEj3XSnDgW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class expm_retraction():\n",
        "    \"\"\"the exmp retraction of a matrix Lie group\n",
        "    this is the most general, and not efficient implementation\n",
        "    for each lie group, we should have a custom implementation of this\n",
        "    \"\"\"\n",
        "    def __init__(self, mnf):\n",
        "        self.mnf = mnf\n",
        "\n",
        "    def retract(self, x, v):\n",
        "        \"\"\"rescaling :math:`x+v` to be on the manifold\n",
        "        \"\"\"\n",
        "        return x@expm(jla.solve(x, v))\n",
        "\n",
        "    def drift_adjust(self, sigma, x, t, driver_dim):\n",
        "        \"\"\"return the adjustment :math:`\\\\mu_{adj}`\n",
        "        so that :math:`\\\\mu + \\\\mu_{adj} = \\\\mu_{\\\\mathfrak{r}}`\n",
        "        \"\"\"\n",
        "\n",
        "        return -0.5*jnp.sum(vmap(lambda seq:\n",
        "                                 x@sqr(jla.solve(x, sigma(x, t, seq.reshape(x.shape)))))(jnp.eye(driver_dim)),\n",
        "                            axis=0)\n",
        "\n",
        "class cayley_so_retraction():\n",
        "    \"\"\"Cayley retraction of a matrix Lie group\n",
        "    this is the most general, and not efficient implementation\n",
        "    for each lie group, we should have a custom implementation of this\n",
        "    \"\"\"\n",
        "    def __init__(self, mnf):\n",
        "        self.mnf = mnf\n",
        "\n",
        "    def retract(self, x, v):\n",
        "        \"\"\"rescaling :math:`x+v` to be on the manifold\n",
        "        \"\"\"\n",
        "        ixv = x.T@v\n",
        "        return x + x@jla.solve(jnp.eye(ixv.shape[0]) - 0.5*ixv, ixv)\n",
        "\n",
        "    def drift_adjust(self, sigma, x, t, driver_dim):\n",
        "        \"\"\"return the adjustment :math:`\\\\mu_{adj}`\n",
        "        so that :math:`\\\\mu + \\\\mu_{adj} = \\\\mu_{\\\\mathfrak{r}}`\n",
        "        \"\"\"\n",
        "        return -0.5*jnp.sum(vmap(lambda seq:\n",
        "                                 x@sqr(self.mnf.sigma_id(seq.reshape(x.shape)))\n",
        "                                 )(jnp.eye(driver_dim)),\n",
        "                            axis=0)\n",
        "\n",
        "def sqr(a):\n",
        "  return a@a"
      ],
      "metadata": {
        "id": "7A5PZbZ1msZg"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Test for $SO(n)$\n",
        "We test the adjusted ito_drift is tangent, double check that it is -sum of gamma."
      ],
      "metadata": {
        "id": "umfUNVfXwe8v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def test_expm_integrator_so():\n",
        "    n = 5\n",
        "    key = random.PRNGKey(0)\n",
        "    so_dim = n*(n-1)//2\n",
        "    metric_mat, key = rand_positive_definite(key, so_dim, (.1, 10.))\n",
        "    mnf = som.SOLeftInvariant(n, metric_mat)\n",
        "    x, key = mnf.rand_point(key)\n",
        "\n",
        "    gsum = jnp.zeros((n, n))\n",
        "    hsum = jnp.zeros((n, n))\n",
        "    for i in range(n**2):\n",
        "        nsg = mnf.proj(x, mnf.sigma(x, jnp.zeros(n**2).at[i].set(1.).reshape(n, n)))\n",
        "        hsum += x@sqr(x.T@nsg)\n",
        "        gsum += - mnf.gamma(x, nsg, nsg)\n",
        "        # print(jnp.sum(mnf.grad_c(x)*(hsum-gsum)))\n",
        "\n",
        "    print(f\"test sum -gamma - ito drift={0.5*gsum - mnf.ito_drift(x)}\")\n",
        "    print(f\"test adjusted ito is tangent={sym(x.T@(-0.5*hsum+mnf.ito_drift(x)))}\")\n",
        "\n",
        "    # now test the equation.\n",
        "    # test Brownian motion\n",
        "    def new_sigma(x, _, dw):\n",
        "        return mnf.proj(x, mnf.sigma(x, dw))\n",
        "\n",
        "    def mu(x, _):\n",
        "        return mnf.ito_drift(x)\n",
        "\n",
        "    pay_offs = [lambda x, t: t*jnp.sum(x*jnp.arange(n)),\n",
        "                lambda x: jnp.sqrt(jnp.sum(x*x))]\n",
        "\n",
        "    key, sk = random.split(key)\n",
        "    t_final = 1.\n",
        "    n_path = 1000\n",
        "    n_div = 1000\n",
        "    d_coeff = .5\n",
        "    wiener_dim = n**2\n",
        "    x_0 = jnp.eye(n)\n",
        "\n",
        "    ret_geo = sim.simulate(x_0,\n",
        "                           lambda x, unit_move, scale: mi.geodesic_move(\n",
        "                               mnf, x, unit_move, scale),\n",
        "                           pay_offs[0],\n",
        "                           pay_offs[1],\n",
        "                           [sk, t_final, n_path, n_div, d_coeff, wiener_dim])\n",
        "\n",
        "    ret_ito = sim.simulate(x_0,\n",
        "                           lambda x, unit_move, scale: mi.rbrownian_ito_move(\n",
        "                               mnf, x, unit_move, scale),\n",
        "                           pay_offs[0],\n",
        "                           pay_offs[1],\n",
        "                           [sk, t_final, n_path, n_div, d_coeff, wiener_dim])\n",
        "\n",
        "    ret_str = sim.simulate(x_0,\n",
        "                           lambda x, unit_move, scale: mi.rbrownian_stratonovich_move(\n",
        "                               mnf, x, unit_move, scale),\n",
        "                           pay_offs[0],\n",
        "                           pay_offs[1],\n",
        "                           [sk, t_final, n_path, n_div, d_coeff, wiener_dim])\n",
        "\n",
        "    rtr = expm_retraction(mnf)\n",
        "    # a warm up run\n",
        "    ret_rtr = sim.simulate(x_0,\n",
        "                           lambda x, unit_move, scale: matrix_retractive_move(\n",
        "                               rtr, x, 1., unit_move, scale, new_sigma, mu),\n",
        "                           pay_offs[0],\n",
        "                           pay_offs[1],\n",
        "                           [sk, t_final, 5, 5, d_coeff, wiener_dim])\n",
        "\n",
        "    t0 = perf_counter()\n",
        "    ret_rtr = sim.simulate(x_0,\n",
        "                           lambda x, unit_move, scale: matrix_retractive_move(\n",
        "                               rtr, x, 1., unit_move, scale, new_sigma, mu),\n",
        "                           pay_offs[0],\n",
        "                           pay_offs[1],\n",
        "                           [sk, t_final, n_path, n_div, d_coeff, wiener_dim])\n",
        "    t1 = perf_counter()\n",
        "    print('Time rtr %f' % (t1-t0))\n",
        "\n",
        "    crtr = cayley_so_retraction(mnf)\n",
        "    t4 = perf_counter()\n",
        "    ret_crtr = sim.simulate(x_0,\n",
        "                           lambda x, unit_move, scale: matrix_retractive_move(\n",
        "                               crtr, x, 1., unit_move, scale, new_sigma, mu),\n",
        "                           pay_offs[0],\n",
        "                           pay_offs[1],\n",
        "                           [sk, t_final, n_path, n_div, d_coeff, wiener_dim])\n",
        "    t5 = perf_counter()\n",
        "    print('Time crtr %f' % (t5-t4))\n",
        "\n",
        "    print(f\"geo second order = {jnp.nanmean(ret_geo[0])}\")\n",
        "    print(f\"Ito              = {jnp.nanmean(ret_ito[0])}\")\n",
        "    print(f\"Stratonovich     = {jnp.nanmean(ret_str[0])}\")\n",
        "    print(f\"Retractive       = {jnp.nanmean(ret_rtr[0])}\")\n",
        "    print(f\"expm_so_Retractive       = {jnp.nanmean(ret_rtr[0])}\")\n",
        "    print(f\"Cayley Retractive       = {jnp.nanmean(ret_crtr[0])}\")\n",
        "\n",
        "test_expm_integrator_so()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hp0BDZJowmDX",
        "outputId": "12afeaf4-60f7-4f7d-d041-d7a3eb38925b"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "test sum -gamma - ito drift=[[ 3.46944695e-16 -6.93889390e-17 -5.55111512e-17  2.77555756e-17\n",
            "  -1.04083409e-17]\n",
            " [-5.72458747e-17  3.60822483e-16  0.00000000e+00  2.77555756e-17\n",
            "   2.22044605e-16]\n",
            " [-5.20417043e-17  2.22044605e-16 -5.55111512e-17  9.71445147e-17\n",
            "   1.94289029e-16]\n",
            " [ 6.93889390e-17 -1.38777878e-17 -4.16333634e-17  1.94289029e-16\n",
            "   1.11022302e-16]\n",
            " [-5.55111512e-17  2.77555756e-17  1.66533454e-16  4.16333634e-17\n",
            "  -3.46944695e-17]]\n",
            "test adjusted ito is tangent=[[-4.77257607e-17  6.50674636e-17  1.89911247e-16  1.44996565e-16\n",
            "  -2.18644708e-17]\n",
            " [ 6.50674636e-17 -3.20764925e-17  8.53113921e-18 -1.27781329e-16\n",
            "  -1.46461781e-16]\n",
            " [ 1.89911247e-16  8.53113921e-18 -1.96166997e-16 -1.96229575e-17\n",
            "   5.03222025e-17]\n",
            " [ 1.44996565e-16 -1.27781329e-16 -1.96229575e-17 -5.22337541e-17\n",
            "  -1.14971926e-16]\n",
            " [-2.18644708e-17 -1.46461781e-16  5.03222025e-17 -1.14971926e-16\n",
            "  -3.93447870e-16]]\n",
            "Time rtr 70.728604\n",
            "Time crtr 14.665379\n",
            "geo second order = 6.056695178129377\n",
            "Ito              = 6.055929373235797\n",
            "Stratonovich     = 6.054953057202998\n",
            "Retractive       = 6.055528965229489\n",
            "expm_so_Retractive       = 6.055528965229489\n",
            "Cayley Retractive       = 6.05581697657123\n"
          ]
        }
      ]
    }
  ]
}